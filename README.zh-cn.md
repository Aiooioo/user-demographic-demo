# 广告平台用户画像系统原型 (User Profile System Demo)

本项目是一个专为广告平台设计的用户画像系统原型演示。它展示了一个完整的端到端数据管道，通过实时和离线两种模式处理用户行为事件，以生成有价值的用户画像标签。这些标签可供下游系统（如广告竞价服务）使用，以支持毫秒级的精准决策。

## 项目目标

本项目的核心目标是演示如何构建一个可扩展、高响应的用户画像系统，其过程包括：

1.  **数据采集**: 接入高吞吐量的用户行为事件（如曝光、点击、购买）。
2.  **数据处理**: 通过两条并行的流水线处理这些事件：
    *   一条 **实时流处理** 路径，用于生成即时的、短期的用户行为标签（例如：“最近5分钟点击次数”）。
    *   一条 **离线批处理** 路径，用于计算长期的、计算密集型的用户价值标签（例如：“用户终身价值总额”）。
3.  **数据融合**: 将实时和离线标签合并成一个统一的用户画像。
4.  **数据服务**: 通过低延迟的 API 提供统一的用户画像数据。

## 核心功能

- **微服务架构**: 系统被解耦为多个专门的服务，以提高可扩展性和可维护性。
- **双数据处理模式**: 使用 Apache Flink 同时实现了流处理（实时）和批处理（离线）两种模式。
- **实时画像标签**: 根据用户最近的活动生成标签（例如 `views_5m`, `clicks_24h`）。
- **离线画像标签**: 计算用户的长期指标（例如 `ltv_total`, `segment_id`）。
- **统一画像接口**: 单个 API 端点为任何用户提供实时和离线标签的融合视图。
- **模拟数据生成**: 项目内置一个 Python 脚本，可轻松生成模拟用户事件数据用于测试。

## 系统架构

系统由多个微服务和数据基础设施组件协同工作。

```
+-----------------+      +------------------+      +---------------------+
|   事件模拟器    |----->|  profile-gateway |----->|  profile-collector  |
| (user-events.py)|      |   (API 网关)     |      |    (事件采集服务)   |
+-----------------+      +------------------+      +---------------------+
                                                          |
                                                          |
                                     +--------------------+--------------------+
                                     | (写入)             | (写入)             |
                                     v                    v                    v
                              +------------+      +----------------+      +-----------+
                              | ODS 文件   |      |   Kafka 主题   |      |   Redis   |
                              | (用于离线) |      |   (用于实时)   |      | (画像存储) |
                              +------------+      +----------------+      +-----------+
                                     ^                    ^                    ^
                                     | (读取)             | (读取)             |
                                     |                    |                    |
      +------------------------+     |                    |     +-------------------------+
      |   Flink 离线任务       |-----+                    +-----|   Flink 实时任务        |
      | (计算 ltv_total)       |                                | (计算 clicks_24h)       |
      +------------------------+                                +-------------------------+
```

### 数据流

1.  **采集**: `user-events.py` 脚本（或任何客户端）将 `AdEvent` JSON 数据发送到 `profile-gateway`。
2.  **收集**: 网关将请求转发到 `profile-collector`。该服务将事件持久化到两个地方：
    *   发送事件到 **Kafka 主题**，供实时流水线使用。
    *   将事件追加到本地的 **ODS 文件**，供离线流水线使用。
3.  **实时处理**: `FlinkRealtimeProfileJob` 从 Kafka 消费事件，通过滑动窗口计算指标，并将 `clicks_24h` 等标签写入对应用户的 Redis Hash 中。
4.  **离线处理**: 当通过 API 调用触发时，`FlinkOfflineProfileJob` 会读取 ODS 文件中的所有历史数据，计算 `ltv_total` 等长期指标，并将结果标签写入同一个 Redis Hash 中。
5.  **服务**: 客户端请求用户画像，`profile-gateway` 将调用路由到 `profile-service`。该服务从 Redis Hash 中读取用户的所有标签，并将它们作为一个“融合”后的 JSON 对象返回。

## 技术栈

- **后端**: Java 17, Spring Boot 3, Spring Cloud
- **数据处理**: Apache Flink
- **消息队列**: Apache Kafka
- **内存数据库**: Redis
- **构建工具**: Apache Maven
- **容器化**: Docker, Docker Compose
- **服务发现**: Nacos (本项目假定由外部环境提供)

## 快速开始

### 环境要求

- Java 17 (或更高版本)
- Apache Maven 3.6+
- Docker & Docker Compose
- Python 3.x (用于事件模拟器)

### 1. 构建项目

在项目根目录中，编译并打包所有的 Java 模块：

```bash
mvn clean install
```

### 2. 运行基础设施

使用 Docker Compose 启动所需的后端服务 (Kafka 和 Redis)：

```bash
docker-compose up -d
```

### 3. 运行应用服务

每个微服务都是一个独立的 Spring Boot 应用。你需要在不同的终端中分别启动它们。

```bash
# 终端 1: 运行网关
java -jar profile-gateway/target/profile-gateway-*.jar

# 终端 2: 运行采集服务 (该服务会自动启动实时 Flink 任务)
java -jar profile-collector/target/profile-collector-*.jar

# 终端 3: 运行画像服务
java -jar profile-service/target/profile-service-*.jar
```
**注意**: 请确保你的外部 Nacos 服务正在运行，并且应用服务可以访问到它。

## 使用与测试

当所有服务都成功运行后，你可以开始测试完整的数据管道。

### 1. 生成模拟数据

打开一个新的终端，并运行项目提供的 Python 脚本。这将向系统发送连续的用户事件流。

首先，安装所需的库：
```bash
pip install requests
```

然后，运行脚本：
```bash
python scripts/user-events.py
```

### 2. 触发离线批处理任务

让事件模拟器运行一段时间后，ODS 文件中会积累一些数据。使用以下命令来触发离线处理任务：

```bash
curl -X POST http://localhost:8080/collect/batch
```

### 3. 查询用户画像

等待几分钟，以便实时和离线任务处理数据。然后，你可以查询任何用户ID（例如 `user-101`）的统一画像。

```bash
curl http://localhost:8080/profile/user-101
```

你应该会收到一个包含实时和离线标签的 JSON 响应，例如：

```json
{
  "views_5m": "3",
  "clicks_24h": "1",
  "ltv_total": "470.5",
  "segment_id": "high_value_user"
}
```
这个结果确认了整个数据流按预期正常工作。
